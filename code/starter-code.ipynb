{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: SAT & ACT Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first markdown cell in a notebook is a great place to provide an overview of your entire project. You will likely want to at least state your\n",
    "\n",
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as well as an"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "\n",
    "If you want to, it's great to use relative links to direct your audience to various sections of a notebook. **HERE'S A DEMONSTRATION WITH THE CURRENT SECTION HEADERS**:\n",
    "\n",
    "### Contents:\n",
    "- [2017 Data Import & Cleaning](#Data-Import-and-Cleaning)\n",
    "- [2018 Data Import and Cleaning](#2018-Data-Import-and-Cleaning)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Data Visualization](#Visualize-the-data)\n",
    "- [Descriptive and Inferential Statistics](#Descriptive-and-Inferential-Statistics)\n",
    "- [Outside Research](#Outside-Research)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you combine your problem statement, executive summary, data dictionary, and conclusions/recommendations, you have an amazing README.md file that quickly aligns your audience to the contents of your project.** Don't forget to cite your data sources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All libraries used should be added here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2017 Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Read In SAT & ACT  Data\n",
    "\n",
    "Read in the `sat_2017.csv` and `act_2017.csv` files and assign them to appropriately named pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code:\n",
    "sat_2017 = pd.read_csv(\"../data/sat_2017.csv\")\n",
    "act_2017 = pd.read_csv(\"../data/act_2017.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Display Data\n",
    "\n",
    "Print the first 10 rows of each dataframe to your jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5%</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>38%</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>30%</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3%</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>53%</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>11%</td>\n",
       "      <td>606</td>\n",
       "      <td>595</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>100%</td>\n",
       "      <td>530</td>\n",
       "      <td>512</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>100%</td>\n",
       "      <td>503</td>\n",
       "      <td>492</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>100%</td>\n",
       "      <td>482</td>\n",
       "      <td>468</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>83%</td>\n",
       "      <td>520</td>\n",
       "      <td>497</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  State Participation  Evidence-Based Reading and Writing  \\\n",
       "0               Alabama            5%                                 593   \n",
       "1                Alaska           38%                                 547   \n",
       "2               Arizona           30%                                 563   \n",
       "3              Arkansas            3%                                 614   \n",
       "4            California           53%                                 531   \n",
       "5              Colorado           11%                                 606   \n",
       "6           Connecticut          100%                                 530   \n",
       "7              Delaware          100%                                 503   \n",
       "8  District of Columbia          100%                                 482   \n",
       "9               Florida           83%                                 520   \n",
       "\n",
       "   Math  Total  \n",
       "0   572   1165  \n",
       "1   533   1080  \n",
       "2   553   1116  \n",
       "3   594   1208  \n",
       "4   524   1055  \n",
       "5   595   1201  \n",
       "6   512   1041  \n",
       "7   492    996  \n",
       "8   468    950  \n",
       "9   497   1017  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code:\n",
    "sat_2017.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National</td>\n",
       "      <td>60%</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>65%</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>62%</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>California</td>\n",
       "      <td>31%</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>100%</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.3</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>31%</td>\n",
       "      <td>25.5</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>18%</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>32%</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  State Participation  English  Math  Reading  Science  \\\n",
       "0              National           60%     20.3  20.7     21.4     21.0   \n",
       "1               Alabama          100%     18.9  18.4     19.7     19.4   \n",
       "2                Alaska           65%     18.7  19.8     20.4     19.9   \n",
       "3               Arizona           62%     18.6  19.8     20.1     19.8   \n",
       "4              Arkansas          100%     18.9  19.0     19.7     19.5   \n",
       "5            California           31%     22.5  22.7     23.1     22.2   \n",
       "6              Colorado          100%     20.1  20.3     21.2     20.9   \n",
       "7           Connecticut           31%     25.5  24.6     25.6     24.6   \n",
       "8              Delaware           18%     24.1  23.4     24.8     23.6   \n",
       "9  District of Columbia           32%     24.4  23.5     24.9     23.5   \n",
       "\n",
       "  Composite  \n",
       "0      21.0  \n",
       "1      19.2  \n",
       "2      19.8  \n",
       "3      19.7  \n",
       "4      19.4  \n",
       "5      22.8  \n",
       "6      20.8  \n",
       "7      25.2  \n",
       "8      24.1  \n",
       "9      24.2  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2017.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Verbally Describe Data\n",
    "\n",
    "Take your time looking through the data and thoroughly describe the data in the markdown cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                                 object\n",
       "Participation                         object\n",
       "Evidence-Based Reading and Writing     int64\n",
       "Math                                   int64\n",
       "Total                                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2017.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State             object\n",
       "Participation     object\n",
       "English          float64\n",
       "Math             float64\n",
       "Reading          float64\n",
       "Science          float64\n",
       "Composite         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2017.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The data are tables with string containing the states including DC and a National roundup. There is a participation rate in string form. There are also what appear to be mean scores for each subject area, including the cumulative total. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4a. Does the data look complete? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Yes, given a lack of Null/NAN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                                 0\n",
       "Participation                         0\n",
       "Evidence-Based Reading and Writing    0\n",
       "Math                                  0\n",
       "Total                                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2017.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State            0\n",
       "Participation    0\n",
       "English          0\n",
       "Math             0\n",
       "Reading          0\n",
       "Science          0\n",
       "Composite        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2017.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b. Are there any obvious issues with the observations?\n",
    "\n",
    "**What is the minimum *possible* value for each test/subtest? What is the maximum *possible* value?**\n",
    "\n",
    "Consider comparing any questionable values to the sources of your data:\n",
    "- [SAT](https://blog.collegevine.com/here-are-the-average-sat-scores-by-state/)\n",
    "- [ACT](https://blog.prepscholar.com/act-scores-by-state-averages-highs-and-lows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.919231</td>\n",
       "      <td>21.173077</td>\n",
       "      <td>22.001923</td>\n",
       "      <td>21.040385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.332132</td>\n",
       "      <td>1.963602</td>\n",
       "      <td>2.048672</td>\n",
       "      <td>3.151113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.300000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>20.475000</td>\n",
       "      <td>19.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.550000</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>21.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.300000</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>24.125000</td>\n",
       "      <td>22.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25.500000</td>\n",
       "      <td>25.300000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>24.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         English       Math    Reading    Science\n",
       "count  52.000000  52.000000  52.000000  52.000000\n",
       "mean   20.919231  21.173077  22.001923  21.040385\n",
       "std     2.332132   1.963602   2.048672   3.151113\n",
       "min    16.300000  18.000000  18.100000   2.300000\n",
       "25%    19.000000  19.400000  20.475000  19.900000\n",
       "50%    20.550000  20.900000  21.700000  21.150000\n",
       "75%    23.300000  23.100000  24.125000  22.525000\n",
       "max    25.500000  25.300000  26.000000  24.900000"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2017.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>569.117647</td>\n",
       "      <td>547.627451</td>\n",
       "      <td>1126.098039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45.666901</td>\n",
       "      <td>84.909119</td>\n",
       "      <td>92.494812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>482.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>533.500000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>1055.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>559.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>613.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>644.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>1295.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Evidence-Based Reading and Writing        Math        Total\n",
       "count                           51.000000   51.000000    51.000000\n",
       "mean                           569.117647  547.627451  1126.098039\n",
       "std                             45.666901   84.909119    92.494812\n",
       "min                            482.000000   52.000000   950.000000\n",
       "25%                            533.500000  522.000000  1055.500000\n",
       "50%                            559.000000  548.000000  1107.000000\n",
       "75%                            613.000000  599.000000  1212.000000\n",
       "max                            644.000000  651.000000  1295.000000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2017.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4c. Fix any errors you identified\n",
    "\n",
    "**The data is available** so there's no need to guess or calculate anything. If you didn't find any errors, continue to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What are your data types? \n",
    "Display the data types of each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State             object\n",
       "Participation     object\n",
       "English          float64\n",
       "Math             float64\n",
       "Reading          float64\n",
       "Science          float64\n",
       "Composite         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code\n",
    "act_2017.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                                 object\n",
       "Participation                         object\n",
       "Evidence-Based Reading and Writing     int64\n",
       "Math                                   int64\n",
       "Total                                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2017.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did you learn?\n",
    "- Do any of them seem odd?  \n",
    "- Which ones are not as they should be?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: I will need to convert the percenage columns into scaled 0-1.0 decimals from strings. Composite score of SATs is an object which means there's some strings in there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Fix Incorrect Data Types\n",
    "Based on what you discovered above, use appropriate methods to re-type incorrectly typed data.\n",
    "- Define a function that will allow you to convert participation rates to an appropriate numeric type. Use `map` or `apply` to change these columns in each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to take a string with a number\n",
    "#followed by a % sign, strip the % and convert it to\n",
    "#an int\n",
    "def str_percentage_to_int(string):\n",
    "    return(int(string.replace(\"%\",\"\")))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National</td>\n",
       "      <td>60</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>65</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>62</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      State  Participation  English  Math  Reading  Science Composite\n",
       "0  National             60     20.3  20.7     21.4     21.0      21.0\n",
       "1   Alabama            100     18.9  18.4     19.7     19.4      19.2\n",
       "2    Alaska             65     18.7  19.8     20.4     19.9      19.8\n",
       "3   Arizona             62     18.6  19.8     20.1     19.8      19.7\n",
       "4  Arkansas            100     18.9  19.0     19.7     19.5      19.4"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2017['Participation'] = act_2017['Participation'].apply(str_percentage_to_int)\n",
    "act_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>38</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>30</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>53</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State  Participation  Evidence-Based Reading and Writing  Math  Total\n",
       "0     Alabama              5                                 593   572   1165\n",
       "1      Alaska             38                                 547   533   1080\n",
       "2     Arizona             30                                 563   553   1116\n",
       "3    Arkansas              3                                 614   594   1208\n",
       "4  California             53                                 531   524   1055"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2017['Participation'] = sat_2017['Participation'].apply(str_percentage_to_int)\n",
    "sat_2017.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fix any individual values preventing other columns from being the appropriate type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51: 20.2x\n"
     ]
    }
   ],
   "source": [
    "#code adapted from Cameron's tutorial on cleaning data\n",
    "\n",
    "for idx, val in act_2017['Composite'].iteritems():\n",
    "    if type(val) != float:\n",
    "        try:\n",
    "            act_2017.loc[idx, 'Composite'] = float(val)\n",
    "        except:\n",
    "            print(f'{idx}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_2017.loc[51, 'Composite'] = 20.2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(act_2017.loc[51, 'Composite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code adapted from Cameron's tutorial on cleaning data\n",
    "#check again!\n",
    "\n",
    "for idx, val in act_2017['Composite'].iteritems():\n",
    "    if type(val) != float:\n",
    "        try:\n",
    "            act_2017.loc[idx, 'Composite'] = float(val)\n",
    "        except:\n",
    "            print(f'{idx}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State             object\n",
       "Participation      int64\n",
       "English          float64\n",
       "Math             float64\n",
       "Reading          float64\n",
       "Science          float64\n",
       "Composite         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2017.dtypes\n",
    "\n",
    "#something didn't work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cast the whole column using .astype\n",
    "act_2017['Composite'] = act_2017['Composite'].astype(dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State             object\n",
       "Participation      int64\n",
       "English          float64\n",
       "Math             float64\n",
       "Reading          float64\n",
       "Science          float64\n",
       "Composite        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2017.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finish your data modifications by making sure the columns are now typed appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "act_2017.columns = act_2017.columns.str.lower()\n",
    "sat_2017.columns = sat_2017.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state', 'participation', 'english', 'math', 'reading', 'science',\n",
       "       'composite'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2017.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state', 'participation', 'evidence-based reading and writing', 'math',\n",
       "       'total'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2017.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the data types again to confirm they are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state             object\n",
       "participation      int64\n",
       "english          float64\n",
       "math             float64\n",
       "reading          float64\n",
       "science          float64\n",
       "composite        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code:\n",
    "act_2017.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                                 object\n",
       "participation                          int64\n",
       "evidence-based reading and writing     int64\n",
       "math                                   int64\n",
       "total                                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2017.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Rename Columns\n",
    "Change the names of the columns to more expressive names so that you can tell the difference the SAT columns and the ACT columns. Your solution should map all column names being changed at once (no repeated singular name-changes). **We will be combining these data with some of the data from 2018, and so you should name columns in an appropriate way**.\n",
    "\n",
    "**Guidelines**:\n",
    "- Column names should be all lowercase (you will thank yourself when you start pushing data to SQL later in the course)\n",
    "- Column names should not contain spaces (underscores will suffice--this allows for using the `df.column_name` method to access columns in addition to `df['column_name']`.\n",
    "- Column names should be unique and informative (the only feature that we actually share between dataframes is the state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remap the column names to allow for future comingling\n",
    "# of data and easier readability\n",
    "act_2017.rename(columns={\n",
    "    'state': 'state',\n",
    "    'participation': 'act_participation_rate_2017',\n",
    "    'english':'act_english_2017',\n",
    "    'math':'act_math_2017',\n",
    "    'reading':'act_reading_2017',\n",
    "    'science':'act_science_2017',\n",
    "    'composite':'act_composite_2017'\n",
    "}, inplace=True)\n",
    "\n",
    "sat_2017.rename(columns={\n",
    "    'state':'state',\n",
    "    'participation':'sat_participation_rate_2017',\n",
    "    'evidence-based reading and writing':'sat_reading_writing_2017',\n",
    "    'math':'sat_math_2017',\n",
    "    'total':'sat_composite_2017'\n",
    "}, inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state', 'act_participation_rate_2017', 'act_english_2017',\n",
       "       'act_math_2017', 'act_reading_2017', 'act_science_2017',\n",
       "       'act_composite_2017'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2017.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state', 'sat_participation_rate_2017', 'sat_reading_writing_2017',\n",
       "       'sat_math_2017', 'sat_composite_2017'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2017.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Create a data dictionary\n",
    "\n",
    "Now that we've fixed our data, and given it appropriate names, let's create a [data dictionary](http://library.ucmerced.edu/node/10249). \n",
    "\n",
    "A data dictionary provides a quick overview of features/variables/columns, alongside data types and descriptions. The more descriptive you can be, the more useful this document is.\n",
    "\n",
    "Example of a Fictional Data Dictionary Entry: \n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|**county_pop**|*integer*|2010 census|The population of the county (units in thousands, where 2.5 represents 2500 people).| \n",
    "|**per_poverty**|*float*|2010 census|The percent of the county over the age of 18 living below the 200% of official US poverty rate (units percent to two decimal places 98.10 means 98.1%)|\n",
    "\n",
    "[Here's a quick link to a short guide for formatting markdown in Jupyter notebooks](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html).\n",
    "\n",
    "Provided is the skeleton for formatting a markdown table, with columns headers that will help you create a data dictionary to quickly summarize your data, as well as some examples. **This would be a great thing to copy and paste into your custom README for this project.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|column name|int/float/object|ACT/SAT|This is an example|\n",
    "state|object|both|The name of the state that the data refers to\n",
    "act_participation_rate_2017|float|ACT|The percentage rate of participation\n",
    "act_english_2017|float|ACT|The average score for the English subtest in 2017\n",
    "act_math_2017|float|ACT|The average score for the Math subtest in 2017\n",
    "\n",
    "    'reading':'act_reading_2017',\n",
    "    'science':'act_science_2017',\n",
    "    'composite':'act_composite_2017'\n",
    "        'state':'state',\n",
    "    'participation':'sat_participation_rate_2017',\n",
    "    'evidence-based reading and writing':'sat_reading_writing_2017',\n",
    "    'math':'sat_math_2017',\n",
    "    'total':'sat_composite_2017'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Drop unnecessary rows\n",
    "\n",
    "One of our dataframes contains an extra row. Identify and remove this from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "act_2017.drop([0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Merge Dataframes\n",
    "\n",
    "Join the 2017 ACT and SAT dataframes using the state in each dataframe as the key. Assign this to a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code:\n",
    "combined_2017 = act_2017.merge(sat_2017,left_on='state', right_on='state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Save your cleaned, merged dataframe\n",
    "\n",
    "Use a relative path to save out your data as `combined_2017.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "combined_2017.to_csv(\"../data/combined_2017.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2018 Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links to the 2018 ACT and SAT data are provided in the README. These data live in PDFs, and so you'll get to enjoy practicing some *manual* data collection. Save these data as a CSV in your `data` directory, and import, explore, and clean these data in the same way you did above. **Make sure you comment on your steps so it is clear *why* you are doing each process**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_2018 = pd.read_csv(\"../data/act_2018.csv\")\n",
    "sat_2018 = pd.read_csv(\"../data/sat_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>33%</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>66%</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>27%</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State Participation  Composite\n",
       "0     Alabama          100%       19.1\n",
       "1      Alaska           33%       20.8\n",
       "2     Arizona           66%       19.2\n",
       "3    Arkansas          100%       19.4\n",
       "4  California           27%       22.7"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert participation rates into ints\n",
    "act_2018['Participation'] = act_2018['Participation'].apply(str_percentage_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chance column names to lowercase and co-existence with other columns\n",
    "act_2018.rename(columns={\n",
    "    'State': 'state',\n",
    "    'Participation': 'act_participation_rate_2018',\n",
    "    'Composite':'act_composite_2018'\n",
    "}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                           object\n",
       "act_participation_rate_2018      int64\n",
       "act_composite_2018             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check datatypes - all looks good!\n",
    "act_2018.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 3)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2018.head()\n",
    "act_2018.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Maine                   2\n",
       "Alaska                  1\n",
       "Ohio                    1\n",
       "Massachusetts           1\n",
       "Wisconsin               1\n",
       "New Jersey              1\n",
       "Florida                 1\n",
       "Maryland                1\n",
       "Montana                 1\n",
       "Arkansas                1\n",
       "Kentucky                1\n",
       "Indiana                 1\n",
       "Wyoming                 1\n",
       "Virginia                1\n",
       "South Carolina          1\n",
       "Hawaii                  1\n",
       "North Dakota            1\n",
       "Pennsylvania            1\n",
       "Michigan                1\n",
       "Nevada                  1\n",
       "North Carolina          1\n",
       "Minnesota               1\n",
       "District of columbia    1\n",
       "New Hampshire           1\n",
       "Alabama                 1\n",
       "Idaho                   1\n",
       "New Mexico              1\n",
       "Connecticut             1\n",
       "Iowa                    1\n",
       "Illinois                1\n",
       "Rhode Island            1\n",
       "Texas                   1\n",
       "Oklahoma                1\n",
       "Colorado                1\n",
       "Nebraska                1\n",
       "Missouri                1\n",
       "West Virginia           1\n",
       "Utah                    1\n",
       "Delaware                1\n",
       "Georgia                 1\n",
       "Washington              1\n",
       "Arizona                 1\n",
       "Louisiana               1\n",
       "Vermont                 1\n",
       "Oregon                  1\n",
       "South Dakota            1\n",
       "Kansas                  1\n",
       "Tennessee               1\n",
       "California              1\n",
       "New York                1\n",
       "Mississippi             1\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2018['state'].value_counts()\n",
    "#There are two Maines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>act_participation_rate_2018</th>\n",
       "      <th>act_composite_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Maine</td>\n",
       "      <td>7</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Maine</td>\n",
       "      <td>7</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    state  act_participation_rate_2018  act_composite_2018\n",
       "19  Maine                            7                24.0\n",
       "20  Maine                            7                24.0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to see what data is there\n",
    "act_2018[act_2018['state'] == 'Maine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicate values\n",
    "act_2018.drop_duplicates('state', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 3)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2018.shape\n",
    "#now it looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>6%</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>43%</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>29%</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>5%</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>60%</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State Participation  Evidence-Based Reading and Writing  Math  Total\n",
       "0     Alabama            6%                                 595   571   1166\n",
       "1      Alaska           43%                                 562   544   1106\n",
       "2     Arizona           29%                                 577   572   1149\n",
       "3    Arkansas            5%                                 592   576   1169\n",
       "4  California           60%                                 540   536   1076"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert participation rates into ints\n",
    "sat_2018['Participation'] = sat_2018['Participation'].apply(str_percentage_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chance column names to lowercase and co-existence with other columns\n",
    "\n",
    "sat_2018.rename(columns={\n",
    "    'State':'state',\n",
    "    'Participation':'sat_participation_rate_2018',\n",
    "    'Evidence-Based Reading and Writing':'sat_reading_writing_2018',\n",
    "    'Math':'sat_math_2018',\n",
    "    'Total':'sat_composite_2018'\n",
    "}, inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                          object\n",
       "sat_participation_rate_2018     int64\n",
       "sat_reading_writing_2018        int64\n",
       "sat_math_2018                   int64\n",
       "sat_composite_2018              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check datatypes - all looks good!\n",
    "sat_2018.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 5)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2018.head()\n",
    "sat_2018.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine your 2017 and 2018 data into a single dataframe\n",
    "Joining on state names should work, assuming you formatted all your state names identically. Make sure none of your columns (other than state) have identical names. Do yourself a favor and decide if you're encoding participation rates as floats or integers and standardize this across your datasets.\n",
    "\n",
    "Save the contents of this merged dataframe as `final.csv`.\n",
    "\n",
    "**Use this combined dataframe for the remainder of the project**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_2018 = act_2018.merge(sat_2018,left_on='state', right_on='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined_2018.merge(combined_2017,left_on='state',right_on='state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>act_participation_rate_2018</th>\n",
       "      <th>act_composite_2018</th>\n",
       "      <th>sat_participation_rate_2018</th>\n",
       "      <th>sat_reading_writing_2018</th>\n",
       "      <th>sat_math_2018</th>\n",
       "      <th>sat_composite_2018</th>\n",
       "      <th>act_participation_rate_2017</th>\n",
       "      <th>act_english_2017</th>\n",
       "      <th>act_math_2017</th>\n",
       "      <th>act_reading_2017</th>\n",
       "      <th>act_science_2017</th>\n",
       "      <th>act_composite_2017</th>\n",
       "      <th>sat_participation_rate_2017</th>\n",
       "      <th>sat_reading_writing_2017</th>\n",
       "      <th>sat_math_2017</th>\n",
       "      <th>sat_composite_2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100</td>\n",
       "      <td>19.1</td>\n",
       "      <td>6</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "      <td>100</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "      <td>5</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>33</td>\n",
       "      <td>20.8</td>\n",
       "      <td>43</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "      <td>65</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "      <td>38</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>66</td>\n",
       "      <td>19.2</td>\n",
       "      <td>29</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "      <td>62</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>30</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100</td>\n",
       "      <td>19.4</td>\n",
       "      <td>5</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1169</td>\n",
       "      <td>100</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "      <td>3</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>27</td>\n",
       "      <td>22.7</td>\n",
       "      <td>60</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "      <td>31</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>53</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  act_participation_rate_2018  act_composite_2018  \\\n",
       "0     Alabama                          100                19.1   \n",
       "1      Alaska                           33                20.8   \n",
       "2     Arizona                           66                19.2   \n",
       "3    Arkansas                          100                19.4   \n",
       "4  California                           27                22.7   \n",
       "\n",
       "   sat_participation_rate_2018  sat_reading_writing_2018  sat_math_2018  \\\n",
       "0                            6                       595            571   \n",
       "1                           43                       562            544   \n",
       "2                           29                       577            572   \n",
       "3                            5                       592            576   \n",
       "4                           60                       540            536   \n",
       "\n",
       "   sat_composite_2018  act_participation_rate_2017  act_english_2017  \\\n",
       "0                1166                          100              18.9   \n",
       "1                1106                           65              18.7   \n",
       "2                1149                           62              18.6   \n",
       "3                1169                          100              18.9   \n",
       "4                1076                           31              22.5   \n",
       "\n",
       "   act_math_2017  act_reading_2017  act_science_2017  act_composite_2017  \\\n",
       "0           18.4              19.7              19.4                19.2   \n",
       "1           19.8              20.4              19.9                19.8   \n",
       "2           19.8              20.1              19.8                19.7   \n",
       "3           19.0              19.7              19.5                19.4   \n",
       "4           22.7              23.1              22.2                22.8   \n",
       "\n",
       "   sat_participation_rate_2017  sat_reading_writing_2017  sat_math_2017  \\\n",
       "0                            5                       593            572   \n",
       "1                           38                       547            533   \n",
       "2                           30                       563            553   \n",
       "3                            3                       614            594   \n",
       "4                           53                       531            524   \n",
       "\n",
       "   sat_composite_2017  \n",
       "0                1165  \n",
       "1                1080  \n",
       "2                1116  \n",
       "3                1208  \n",
       "4                1055  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 17)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv(\"../data/final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "\n",
    "### Summary Statistics\n",
    "Transpose the output of pandas `describe` method to create a quick overview of each numeric feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>16</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>100</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.4</td>\n",
       "      <td>22.7</td>\n",
       "      <td>100</td>\n",
       "      <td>25.6</td>\n",
       "      <td>24.1</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>20.7</td>\n",
       "      <td>100</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.5</td>\n",
       "      <td>21.9</td>\n",
       "      <td>1086</td>\n",
       "      <td>20.5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1     2     3     4    5     6     7     8     9   ...  40  \\\n",
       "count    17  17.0  17.0  17.0  17.0   17  17.0  17.0  17.0  17.0  ...  17   \n",
       "unique   16  16.0  16.0  15.0  16.0   16  14.0  14.0  16.0  16.0  ...  16   \n",
       "top     100  19.8  19.8  19.4  22.7  100  25.6  24.1  19.4  21.4  ...   3   \n",
       "freq      2   2.0   2.0   2.0   2.0    2   2.0   2.0   2.0   2.0  ...   2   \n",
       "\n",
       "         41    42   43    44    45    46    47    48   49  \n",
       "count    17  17.0   17  17.0  17.0  17.0    17  17.0   17  \n",
       "unique   16  14.0   16  17.0  16.0  16.0    17  14.0   15  \n",
       "top     100  20.7  100  24.1  23.5  21.9  1086  20.5  100  \n",
       "freq      2   3.0    2   1.0   2.0   2.0     1   2.0    2  \n",
       "\n",
       "[4 rows x 50 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code:\n",
    "combined.T.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually calculate standard deviation\n",
    "\n",
    "$$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2}$$\n",
    "\n",
    "- Write a function to calculate standard deviation using the formula above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "#quick reminder of st dev from https://revisionmaths.com/gcse-maths-revision/statistics-handling-data/standard-deviation\n",
    "\n",
    "def st_dev(array):\n",
    "    total= 0\n",
    "    mean = np.mean(array)\n",
    "    for n in array:\n",
    "        total+=(mean - n)**2\n",
    "    return((total / len(array))**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>California</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>...</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Washington</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_participation_rate_2018</th>\n",
       "      <td>100</td>\n",
       "      <td>33</td>\n",
       "      <td>66</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>66</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>100</td>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>65</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_composite_2018</th>\n",
       "      <td>19.1</td>\n",
       "      <td>20.8</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.4</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.9</td>\n",
       "      <td>25.6</td>\n",
       "      <td>23.8</td>\n",
       "      <td>19.9</td>\n",
       "      <td>21.4</td>\n",
       "      <td>...</td>\n",
       "      <td>21.9</td>\n",
       "      <td>19.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.9</td>\n",
       "      <td>22.2</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat_participation_rate_2018</th>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>56</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat_reading_writing_2018</th>\n",
       "      <td>595</td>\n",
       "      <td>562</td>\n",
       "      <td>577</td>\n",
       "      <td>592</td>\n",
       "      <td>540</td>\n",
       "      <td>519</td>\n",
       "      <td>535</td>\n",
       "      <td>505</td>\n",
       "      <td>550</td>\n",
       "      <td>542</td>\n",
       "      <td>...</td>\n",
       "      <td>622</td>\n",
       "      <td>624</td>\n",
       "      <td>520</td>\n",
       "      <td>480</td>\n",
       "      <td>565</td>\n",
       "      <td>567</td>\n",
       "      <td>543</td>\n",
       "      <td>513</td>\n",
       "      <td>641</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat_math_2018</th>\n",
       "      <td>571</td>\n",
       "      <td>544</td>\n",
       "      <td>572</td>\n",
       "      <td>576</td>\n",
       "      <td>536</td>\n",
       "      <td>506</td>\n",
       "      <td>519</td>\n",
       "      <td>492</td>\n",
       "      <td>549</td>\n",
       "      <td>522</td>\n",
       "      <td>...</td>\n",
       "      <td>618</td>\n",
       "      <td>607</td>\n",
       "      <td>512</td>\n",
       "      <td>530</td>\n",
       "      <td>554</td>\n",
       "      <td>550</td>\n",
       "      <td>538</td>\n",
       "      <td>486</td>\n",
       "      <td>653</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat_composite_2018</th>\n",
       "      <td>1166</td>\n",
       "      <td>1106</td>\n",
       "      <td>1149</td>\n",
       "      <td>1169</td>\n",
       "      <td>1076</td>\n",
       "      <td>1025</td>\n",
       "      <td>1053</td>\n",
       "      <td>998</td>\n",
       "      <td>1099</td>\n",
       "      <td>1064</td>\n",
       "      <td>...</td>\n",
       "      <td>1240</td>\n",
       "      <td>1231</td>\n",
       "      <td>1032</td>\n",
       "      <td>1010</td>\n",
       "      <td>1120</td>\n",
       "      <td>1117</td>\n",
       "      <td>1081</td>\n",
       "      <td>999</td>\n",
       "      <td>1294</td>\n",
       "      <td>1257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_participation_rate_2017</th>\n",
       "      <td>100</td>\n",
       "      <td>65</td>\n",
       "      <td>62</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>18</td>\n",
       "      <td>73</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>69</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_english_2017</th>\n",
       "      <td>18.9</td>\n",
       "      <td>18.7</td>\n",
       "      <td>18.6</td>\n",
       "      <td>18.9</td>\n",
       "      <td>22.5</td>\n",
       "      <td>20.1</td>\n",
       "      <td>25.5</td>\n",
       "      <td>24.1</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>20.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.5</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_math_2017</th>\n",
       "      <td>18.4</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19</td>\n",
       "      <td>22.7</td>\n",
       "      <td>20.3</td>\n",
       "      <td>24.6</td>\n",
       "      <td>23.4</td>\n",
       "      <td>19.4</td>\n",
       "      <td>20.9</td>\n",
       "      <td>...</td>\n",
       "      <td>21.5</td>\n",
       "      <td>19.2</td>\n",
       "      <td>20.7</td>\n",
       "      <td>19.9</td>\n",
       "      <td>23.1</td>\n",
       "      <td>23.3</td>\n",
       "      <td>21.9</td>\n",
       "      <td>19.4</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_reading_2017</th>\n",
       "      <td>19.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>21.2</td>\n",
       "      <td>25.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>22.3</td>\n",
       "      <td>20.1</td>\n",
       "      <td>21.1</td>\n",
       "      <td>20.8</td>\n",
       "      <td>24.4</td>\n",
       "      <td>24.6</td>\n",
       "      <td>22.1</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_science_2017</th>\n",
       "      <td>19.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.5</td>\n",
       "      <td>22.2</td>\n",
       "      <td>20.9</td>\n",
       "      <td>24.6</td>\n",
       "      <td>23.6</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.3</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.6</td>\n",
       "      <td>23.2</td>\n",
       "      <td>23.5</td>\n",
       "      <td>22</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_composite_2017</th>\n",
       "      <td>19.2</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>22.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>25.2</td>\n",
       "      <td>24.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>21.4</td>\n",
       "      <td>...</td>\n",
       "      <td>21.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.3</td>\n",
       "      <td>23.6</td>\n",
       "      <td>23.8</td>\n",
       "      <td>21.9</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat_participation_rate_2017</th>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>83</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat_reading_writing_2017</th>\n",
       "      <td>593</td>\n",
       "      <td>547</td>\n",
       "      <td>563</td>\n",
       "      <td>614</td>\n",
       "      <td>531</td>\n",
       "      <td>606</td>\n",
       "      <td>530</td>\n",
       "      <td>503</td>\n",
       "      <td>520</td>\n",
       "      <td>535</td>\n",
       "      <td>...</td>\n",
       "      <td>612</td>\n",
       "      <td>623</td>\n",
       "      <td>513</td>\n",
       "      <td>624</td>\n",
       "      <td>562</td>\n",
       "      <td>561</td>\n",
       "      <td>541</td>\n",
       "      <td>558</td>\n",
       "      <td>642</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat_math_2017</th>\n",
       "      <td>572</td>\n",
       "      <td>533</td>\n",
       "      <td>553</td>\n",
       "      <td>594</td>\n",
       "      <td>524</td>\n",
       "      <td>595</td>\n",
       "      <td>512</td>\n",
       "      <td>492</td>\n",
       "      <td>497</td>\n",
       "      <td>515</td>\n",
       "      <td>...</td>\n",
       "      <td>603</td>\n",
       "      <td>604</td>\n",
       "      <td>507</td>\n",
       "      <td>614</td>\n",
       "      <td>551</td>\n",
       "      <td>541</td>\n",
       "      <td>534</td>\n",
       "      <td>528</td>\n",
       "      <td>649</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat_composite_2017</th>\n",
       "      <td>1165</td>\n",
       "      <td>1080</td>\n",
       "      <td>1116</td>\n",
       "      <td>1208</td>\n",
       "      <td>1055</td>\n",
       "      <td>1201</td>\n",
       "      <td>1041</td>\n",
       "      <td>996</td>\n",
       "      <td>1017</td>\n",
       "      <td>1050</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1228</td>\n",
       "      <td>1020</td>\n",
       "      <td>1238</td>\n",
       "      <td>1114</td>\n",
       "      <td>1102</td>\n",
       "      <td>1075</td>\n",
       "      <td>1086</td>\n",
       "      <td>1291</td>\n",
       "      <td>1230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows  50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0       1        2         3           4   \\\n",
       "state                        Alabama  Alaska  Arizona  Arkansas  California   \n",
       "act_participation_rate_2018      100      33       66       100          27   \n",
       "act_composite_2018              19.1    20.8     19.2      19.4        22.7   \n",
       "sat_participation_rate_2018        6      43       29         5          60   \n",
       "sat_reading_writing_2018         595     562      577       592         540   \n",
       "sat_math_2018                    571     544      572       576         536   \n",
       "sat_composite_2018              1166    1106     1149      1169        1076   \n",
       "act_participation_rate_2017      100      65       62       100          31   \n",
       "act_english_2017                18.9    18.7     18.6      18.9        22.5   \n",
       "act_math_2017                   18.4    19.8     19.8        19        22.7   \n",
       "act_reading_2017                19.7    20.4     20.1      19.7        23.1   \n",
       "act_science_2017                19.4    19.9     19.8      19.5        22.2   \n",
       "act_composite_2017              19.2    19.8     19.7      19.4        22.8   \n",
       "sat_participation_rate_2017        5      38       30         3          53   \n",
       "sat_reading_writing_2017         593     547      563       614         531   \n",
       "sat_math_2017                    572     533      553       594         524   \n",
       "sat_composite_2017              1165    1080     1116      1208        1055   \n",
       "\n",
       "                                   5            6         7        8   \\\n",
       "state                        Colorado  Connecticut  Delaware  Florida   \n",
       "act_participation_rate_2018        30           26        17       66   \n",
       "act_composite_2018               23.9         25.6      23.8     19.9   \n",
       "sat_participation_rate_2018       100          100       100       56   \n",
       "sat_reading_writing_2018          519          535       505      550   \n",
       "sat_math_2018                     506          519       492      549   \n",
       "sat_composite_2018               1025         1053       998     1099   \n",
       "act_participation_rate_2017       100           31        18       73   \n",
       "act_english_2017                 20.1         25.5      24.1       19   \n",
       "act_math_2017                    20.3         24.6      23.4     19.4   \n",
       "act_reading_2017                 21.2         25.6      24.8       21   \n",
       "act_science_2017                 20.9         24.6      23.6     19.4   \n",
       "act_composite_2017               20.8         25.2      24.1     19.8   \n",
       "sat_participation_rate_2017        11          100       100       83   \n",
       "sat_reading_writing_2017          606          530       503      520   \n",
       "sat_math_2017                     595          512       492      497   \n",
       "sat_composite_2017               1201         1041       996     1017   \n",
       "\n",
       "                                  9   ...            40         41     42  \\\n",
       "state                        Georgia  ...  South Dakota  Tennessee  Texas   \n",
       "act_participation_rate_2018       53  ...            77        100     45   \n",
       "act_composite_2018              21.4  ...          21.9       19.6   20.7   \n",
       "sat_participation_rate_2018       70  ...             3          6     66   \n",
       "sat_reading_writing_2018         542  ...           622        624    520   \n",
       "sat_math_2018                    522  ...           618        607    512   \n",
       "sat_composite_2018              1064  ...          1240       1231   1032   \n",
       "act_participation_rate_2017       55  ...            80        100     45   \n",
       "act_english_2017                  21  ...          20.7       19.5   19.5   \n",
       "act_math_2017                   20.9  ...          21.5       19.2   20.7   \n",
       "act_reading_2017                  22  ...          22.3       20.1   21.1   \n",
       "act_science_2017                21.3  ...            22       19.9   20.9   \n",
       "act_composite_2017              21.4  ...          21.8       19.8   20.7   \n",
       "sat_participation_rate_2017       61  ...             3          5     62   \n",
       "sat_reading_writing_2017         535  ...           612        623    513   \n",
       "sat_math_2017                    515  ...           603        604    507   \n",
       "sat_composite_2017              1050  ...          1216       1228   1020   \n",
       "\n",
       "                               43       44        45          46  \\\n",
       "state                        Utah  Vermont  Virginia  Washington   \n",
       "act_participation_rate_2018   100       24        24          24   \n",
       "act_composite_2018           20.4     24.1      23.9        22.2   \n",
       "sat_participation_rate_2018     4       64        68          69   \n",
       "sat_reading_writing_2018      480      565       567         543   \n",
       "sat_math_2018                 530      554       550         538   \n",
       "sat_composite_2018           1010     1120      1117        1081   \n",
       "act_participation_rate_2017   100       29        29          29   \n",
       "act_english_2017             19.5     23.3      23.5        20.9   \n",
       "act_math_2017                19.9     23.1      23.3        21.9   \n",
       "act_reading_2017             20.8     24.4      24.6        22.1   \n",
       "act_science_2017             20.6     23.2      23.5          22   \n",
       "act_composite_2017           20.3     23.6      23.8        21.9   \n",
       "sat_participation_rate_2017     3       60        65          64   \n",
       "sat_reading_writing_2017      624      562       561         541   \n",
       "sat_math_2017                 614      551       541         534   \n",
       "sat_composite_2017           1238     1114      1102        1075   \n",
       "\n",
       "                                        47         48       49  \n",
       "state                        West Virginia  Wisconsin  Wyoming  \n",
       "act_participation_rate_2018             65        100      100  \n",
       "act_composite_2018                    20.3       20.5       20  \n",
       "sat_participation_rate_2018             28          3        3  \n",
       "sat_reading_writing_2018               513        641      633  \n",
       "sat_math_2018                          486        653      625  \n",
       "sat_composite_2018                     999       1294     1257  \n",
       "act_participation_rate_2017             69        100      100  \n",
       "act_english_2017                        20       19.7     19.4  \n",
       "act_math_2017                         19.4       20.4     19.8  \n",
       "act_reading_2017                      21.2       20.6     20.8  \n",
       "act_science_2017                      20.5       20.9     20.6  \n",
       "act_composite_2017                    20.4       20.5     20.2  \n",
       "sat_participation_rate_2017             14          3        3  \n",
       "sat_reading_writing_2017               558        642      626  \n",
       "sat_math_2017                          528        649      604  \n",
       "sat_composite_2017                    1086       1291     1230  \n",
       "\n",
       "[17 rows x 50 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = combined.transpose()\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/dsi/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_monotonic\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_monotonic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'state'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-213-71c5285b9bec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-213-71c5285b9bec>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/dsi/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m             )\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dsi/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_monotonic\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_monotonic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_setop_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'state'"
     ]
    }
   ],
   "source": [
    "{key:combined.T[key] for key in combined.to_dict(orient='state')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use a **dictionary comprehension** to apply your standard deviation function to each numeric column in the dataframe.  **No loops**  \n",
    "- Assign the output to variable `sd` as a dictionary where: \n",
    "    - Each column name is now a key \n",
    "    - That standard deviation of the column is the value \n",
    "     \n",
    "*Example Output :* `{'ACT_Math': 120, 'ACT_Reading': 120, ...}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do your manually calculated standard deviations match up with the output from pandas `describe`? What about numpy's `std` method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate trends in the data\n",
    "Using sorting and/or masking (along with the `.head` method to not print our entire dataframe), consider the following questions:\n",
    "\n",
    "- Which states have the highest and lowest participation rates for the:\n",
    "    - 2017 SAT?\n",
    "    - 2018 SAT?\n",
    "    - 2017 ACT?\n",
    "    - 2018 ACT?\n",
    "- Which states have the highest and lowest mean total/composite scores for the:\n",
    "    - 2017 SAT?\n",
    "    - 2018 SAT?\n",
    "    - 2017 ACT?\n",
    "    - 2018 ACT?\n",
    "- Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "- Do any states show have >50% participation on *both* tests either year?\n",
    "\n",
    "Based on what you've just observed, have you identified any states that you're especially interested in? **Make a note of these and state *why* you think they're interesting**.\n",
    "\n",
    "**You should comment on your findings at each step in a markdown cell below your code block**. Make sure you include at least one example of sorting your dataframe by a column, and one example of using boolean filtering (i.e., masking) to select a subset of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data\n",
    "\n",
    "There's not a magic bullet recommendation for the right number of plots to understand a given dataset, but visualizing your data is *always* a good idea. Not only does it allow you to quickly convey your findings (even if you have a non-technical audience), it will often reveal trends in your data that escaped you when you were looking only at numbers.\n",
    "\n",
    "Some recommendations on plotting:\n",
    "- Plots have titles\n",
    "- Plots have axis labels\n",
    "- Plots have appropriate tick labels\n",
    "- All text is legible in a plot\n",
    "- Plots demonstrate meaningful and valid relationships\n",
    "- Plots are interpreted to aid understanding\n",
    "\n",
    "There is such a thing as too many plots, and there are a *lot* of bad plots. You might make some! (But hopefully not with the guided prompts below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Seaborn's heatmap with pandas `.corr()` to visualize correlations between all numeric features\n",
    "\n",
    "Heatmaps are generally not appropriate for presentations, and should often be excluded from reports as they can be visually overwhelming. **However**, they can be extremely useful in identify relationships of potential interest (as well as identifying potential collinearity before modeling).\n",
    "\n",
    "*example*:\n",
    "```python\n",
    "sns.heatmap(df.corr())\n",
    "```\n",
    "\n",
    "Please take time to format your output, adding a title. Look through some of the additional arguments and options. (Axis labels aren't really necessary, as long as the title is informative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a custom function to subplot histograms\n",
    "\n",
    "We have data for two tests for two years. We only have composite (and not subtest scores) for the 2018 ACT. We should write a function that will take the names of 2+ columns and subplot histograms. While you can use pandas plotting or Seaborn here, matplotlib gives you greater control over all aspects of your plots.\n",
    "\n",
    "[Helpful Link for Plotting Multiple Figures](https://matplotlib.org/users/pyplot_tutorial.html#working-with-multiple-figures-and-axes)\n",
    "\n",
    "Here's some starter code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_histograms(dataframe, list_of_columns, list_of_titles, list_of_xlabels):\n",
    "    nrows = int(np.ceil(len(list_of_columns)/2)) # Makes sure you have enough rows\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=2) # You'll want to specify your figsize\n",
    "    ax = ax.ravel() # Ravel turns a matrix into a vector, which is easier to iterate\n",
    "    for i, column in enumerate(list_of_columns): # Gives us an index value to get into all our lists\n",
    "        ax[i].hist(dataframe[column]) # feel free to add more settings\n",
    "        # Set titles, labels, etc here for each subplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret histograms \n",
    "For each of the following:\n",
    "- Participation rates for SAT & ACT\n",
    "- Math scores for SAT & ACT\n",
    "- Reading/verbal scores for SAT & ACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret scatter plots\n",
    "\n",
    "For each of the following:\n",
    "- SAT vs. ACT math scores for 2017\n",
    "- SAT vs. ACT verbal/reading scores for 2017\n",
    "- SAT vs. ACT total/composite scores for 2017\n",
    "- Total scores for SAT 2017 vs. 2018\n",
    "- Composite scores for ACT 2017 vs. 2018\n",
    "\n",
    "Plot the two variables against each other using matplotlib or Seaborn\n",
    "\n",
    "Your plots should show:\n",
    "- Two clearly labeled axes\n",
    "- A proper title\n",
    "- Using colors and symbols that are clear and unmistakable\n",
    "\n",
    "**Feel free to write a custom function, and subplot if you'd like.** Functions save both time and space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret boxplots\n",
    "\n",
    "For each numeric variable in the dataframe create a boxplot using Seaborn. Boxplots demonstrate central tendency and spread in variables. In a certain sense, these are somewhat redundant with histograms, but you may be better able to identify clear outliers or differences in IQR, etc.\n",
    "\n",
    "Multiple values can be plotted to a single boxplot as long as they are of the same relative scale (meaning they have similar min/max values).\n",
    "\n",
    "Each boxplot should:\n",
    "- Only include variables of a similar scale\n",
    "- Have clear labels for each variable\n",
    "- Have appropriate titles and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feel free to do additional plots below\n",
    "*(do research and choose your own chart types & variables)*\n",
    "\n",
    "Are there any additional trends or relationships you haven't explored? Was there something interesting you saw that you'd like to dive further into? It's likely that there are a few more plots you might want to generate to support your narrative and recommendations that you are building toward. **As always, make sure you're interpreting your plots as you go**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional): Using Tableau, create a choropleth map for each variable using a map of the US. \n",
    "\n",
    "Save this plot as an image file in an images directory, provide a relative path, and insert the image into notebook in markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive and Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarizing Distributions\n",
    "\n",
    "Above, we used pandas `describe` to provide quick summary statistics of our numeric columns. We also demonstrated many visual relationships.\n",
    "\n",
    "As data scientists, having a complete understanding of data is imperative prior to modeling.\n",
    "\n",
    "While we will continue to build our analytic tools, we know that measures of *central tendency*, *spread*, and *shape/skewness* provide a quick summary of distributions.\n",
    "\n",
    "For each variable in your data, summarize the underlying distributions (in words & statistics)\n",
    " - Be thorough in your verbal description of these distributions.\n",
    " - Be sure to back up these summaries with statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We generally assuming that data we sample from a population will be normally distributed. Do we observe this trend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does This Assumption Hold for:\n",
    "    - Math\n",
    "    - Reading\n",
    "    - Rates\n",
    "Explain your answers for each distribution and how you think this will affect estimates made from these data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate Limits of Data\n",
    "\n",
    "Suppose we only seek to understand the relationship between SAT and ACT participation rates in 2017. \n",
    "\n",
    "##### Does it make sense to conduct statistical inference given these data specifically? \n",
    "\n",
    "Why or why not?\n",
    "\n",
    "*(think about granularity, aggregation, the relationships between populations size & rates...consider the actually populations these data describe in answering this question)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Is it appropriate to compare *these* specific SAT and ACT math scores? \n",
    "\n",
    "Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Evaluation of Distributions \n",
    "\n",
    "**If you feel it's appropriate**, using methods we discussed in class, run hypothesis tests to compare variables of interest in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outside Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based upon your observations, choose **three** states that demonstrate interesting trends in their SAT and/or ACT participation rates. Spend some time doing outside research on state policies that might influence these rates, and summarize your findings below. **Feel free to go back and create new plots that highlight these states of interest**. If you bring in any outside tables or charts, make sure you are explicit about having borrowed them. If you quote any text, make sure that it renders as being quoted. (Make sure that you cite your sources -- check with you local instructor for citation preferences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your exploration of the data, what are you key takeaways and recommendations? Choose one state with a lower participation rate and provide a suggestion for how the College Board might increase participation amongst graduating seniors in this state. Are there additional data you desire that would better inform your investigations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
